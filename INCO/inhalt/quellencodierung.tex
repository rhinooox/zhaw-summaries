\section{Quellencodierung}
\subsection{Redundanz}
\subsubsection{Codewortlänge $\ell_n$}
\begin{center}
	\begin{tabular}{ c c c }
		Symbol & Code           & Codewortlänge    \\
		$x_0$  & $c_0 = (10)$   & $\ell_0 = 2 Bit$ \\
		$x_1$  & $c_1 = (110)$  & $\ell_1 = 3 Bit$ \\
		$x_2$  & $c_2 = (1110)$ & $\ell_2 = 4 Bit$
	\end{tabular}
\end{center}
\subsubsection{Mittlere Länge der Codierung $L$}
\begin{equation*}
	L = \sum_{n=0}^{N-1} P(x_n) \cdot \ell_n
\end{equation*}
\subsubsection{Redundanz $R$}
In $Bit/Symbol$:
\begin{equation*}
	R = L - H(X)
\end{equation*}
\subsubsection{Theorem zu Quellencodierung}
\begin{itemize}
	\item Falls $R > 0$, dann kann verlustfrei komprimiert werden.
	\item Falls $R \leq 0$, dann kann nur verlustbehaftet komprimiert werden.
\end{itemize}
\subsection{Kompressionsrate}
\begin{align*}
	R = \frac{\text{Grösse komprimierte Daten}}{\text{Grösse Originaldaten}} \\
	\text{Kompressionsrate } R \neq \text{Redundanz } R
\end{align*}
\subsection{Lauflängencodierung}
Lauflängencodierung oder Run-Length Encoding (RLE) ist eine einfache Methode
zur verlustfreien Datenkompression.
\begin{itemize}
	\item Marker bestimmen, z.B. selten genutzes Zeichen.
	\item Marker und Anzahl der Wiederholungen speichern.
\end{itemize}
\begin{verbatim}
    Hier verwenden wir als Marker z.B. Z:
    Orginal: ASKEEEEEEEEEEFEIIIIIPPPP ...
    Codiert: ASKZ10EZ05IZ04P ...
\end{verbatim}
\subsection{Huffman-Codierung}
Um Huffman-Codierung anzuwenden, muss die Wahrscheinlichkeit $P(x_n)$ der Symbole bekannt sein.
\begin{itemize}
	\item Ordne alle Symbole nach aufsteigenden Auftretenswahrscheinlichkeiten auf einer Zeile. Dies sind die Blätter des Huffman-Baums.
	\item Notiere unter jedes Blatt seine Wahrscheinlichkeit.
	\item Schliesse die beiden Blätter mit der kleinsten Wahrscheinlichkeit an einer gemeinsamen Astgabel an und ordne dem Ast die Summe der Wahrscheinlichkeiten der beiden Blätter zu.
	\item Wiederhole den vorherigen Schritt mit Blättern und Ästen so lange, bis nur noch der Stamm des Baums übrig bleibt.
	\item Nun wird bei jeder Astgabel dem einen Zweig eine 0 und dem anderen eine 1 zugeordnet. (Die Zuordnung ist frei wählbar, muss aber über den ganzen Baum einheitlich sein).
	\item Nun werden auf dem Pfad vom Stamm zu jedem Blatt die Nullen und Einsen ausgelesen und von links nach rechts nebeneinander geschrieben. Dies sind die Huffman-Codeworte.
\end{itemize}
\includegraphics[scale= 0.4]{huffman}
\subsection{LZ77}
Für LZ77 ein Suchbuffer $n_{s}$ und Vorschaubuffer $n_{v}$ definiert.
Der Token hat das Format (Offset, Länge, Zeichen).
\begin{itemize}
    \item Alle Zeichen werden durch Tokens fixer Länge ersetzt.
    \item Zur Bildung der Tokens werden die Daten durch ein Sliding Window, bestehend aus Such- und Vorschaubuffer, geleitet.
    \item Im Such-Buffer wird die längste Übereinstimmung mit dem Vorschau-Buffer als Token ausgegeben.
    \item Keine Übereinstimmung: Token $(0, 0, \text{Zeichen})$ wird verwendet.
\end{itemize}
\begin{center}
	\includegraphics[scale=0.27]{lz77}
\end{center}

\subsubsection{Einzelne Tokengrösse}
\begin{align*}
\text{Grösse Such-Buffer} + \text{Grösse Vorschau-Buffer} + \text{Zusätzliches Zeichen}
\end{align*}

\subsubsection{Gesamt}
\begin{align*}
\text{Anzahl Tokens} \times \text{Tokengrösse}
\end{align*}

\subsubsection{Kompressionsrate}
\begin{align*}
R = \frac{\text{LZ77 Codierung in Bits}}{\text{String ohne Codierung in Bits}}
\end{align*}

\noindent
\textbf{Beim Token:} Die Buffergrösse ist jeweils $\text{roundUp}(\log_2(N))$, wobei $N$ die Zahl ist, bis zu der wir maximal zählen können. \\
Beispiel Such-Buffer (1 bis 10): $\text{roundUp}(\log_2(10)) = 3.321\ldots = 4$ Bit
\subsubsection{Decoding}
\begin{itemize}
	\item Start mit leerem Such-Buffer
	\item Bei Tokens ohne Referenz in den Such-Buffer einfach Zeichen ausgeben und in Such-Buffer schieben
	\item Bei Tokens mit Referenz in den Such-Buffer wird zunächst der referenzierte String ausgegeben und das Symbol im Token
\end{itemize}

\subsection{LZW}
\subsubsection{Verfahren}
\begin{itemize}
	\item Basic vorinitialisiertes Wörterbuch (Bsp: Einzelsymbole von ASCII), Einzelne Zeichen sind immer im Wörterbuch vorhanden!
	\item String von links nach rechts lesen, bis der gelesene Teilstring nicht mehr im Wörterbuch vorkommt
	\item Token enthält nur den Index des schon bestehenden Eintrags im Wörterbuch, nicht aber das neue Zeichen
\end{itemize}
\begin{center}
	\includegraphics[scale=0.5]{lzw1}
\end{center}
\subsubsection{Decoding}
\begin{center}
	\includegraphics[scale=0.6]{lzw2}
\end{center}
Das Zeichen ganz rechts vom Eintrag wird erst bei dem
nächsten Token übertragen (Überlappung)